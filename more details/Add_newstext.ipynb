{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as urlparse\n",
    "import newsapi\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "import tldextract\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from urllib import request\n",
    "import urllib.parse as urlparse\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import tldextract\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_title_text(data_list):\n",
    "    l=[]\n",
    "    for j,i in enumerate(data_list):\n",
    "        print(j)\n",
    "        new_title = \"\"\n",
    "        text = \"\"\n",
    "        url=data_list[j]['links_contained']\n",
    "#        print(url)\n",
    "        try:\n",
    "            html = request.urlopen(url).read().decode('utf8')\n",
    "\n",
    "\n",
    "    #        soup = BeautifulSoup(urlopen(url))\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            title = soup.find('title')\n",
    "            new_title = title.string\n",
    "            text = text_from_html(html)\n",
    "        except:\n",
    "            pass\n",
    "        i['news_text'] = text\n",
    "        l.append(i)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_news_title_text(twitterData) # with the format got from get_data.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
